[project]
name = "qcrawl"
version = "0.3.3"
description = "Fast async web crawler & scraping framework, supporting deduplication, and extensible middleware."
authors = [{ name = "Vasiliy Kiryanov", email = "vasiliy.kiryanov@gmail.com" }]
maintainers = [{name = "Vasiliy Kiryanov", email = "vasiliy.kiryanov@gmail.com"}]
license = { text = "MIT" }
license-files = ["LICENSE"]
readme = { file = "README.md", content-type = "text/markdown" }
requires-python = ">=3.11"
classifiers = [
    "Development Status :: 5 - Production/Stable",
    "Intended Audience :: Developers",
    "Operating System :: OS Independent",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Programming Language :: Python :: 3.14",
    "Topic :: Internet :: WWW/HTTP",
    "Topic :: Software Development :: Libraries :: Application Frameworks",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Framework :: AsyncIO",
    "Typing :: Typed",
]
keywords = [
    "web-scraping",
    "crawler",
    "spider",
    "async",
    "asyncio",
    "scraper",
]

# Core dependencies
dependencies = [
    "aiohttp>=3.10.0", # async HTTP client
    "aiofiles>=24.1.0", # async file operations
    "lxml>=5.3.0", # fast HTML/XML parsing
    "cssselect>=1.2.0", # CSS selectors for lxml
    "yarl>=1.13.0", # URL handling
    "orjson>=3.10.0", # JSON library
    "msgspec>=0.18.0",
    "charset-normalizer>=3.3.2", # encoding detection
]

# Optional dependencies (extras)
[project.optional-dependencies]
redis = [
    "redis>=6.4.0",
]

prometheus = ["prometheus-client>=0.20.0"]
opentelemetry = [
    "opentelemetry-api>=1.27.0",
    "opentelemetry-sdk>=1.27.0",
    "opentelemetry-exporter-otlp-proto-http>=1.27.0"
]
observability = ["qcrawl[prometheus,opentelemetry]"]

dev = [
    "pytest>=8.0",
    "pytest-asyncio>=0.23",
    "pytest-cov>=4.1.0",
    "ruff>=0.1.0",
    "mypy>=1.10",
    "tox>=4.32.0",
    "pre-commit>=3.5.0",
    "types-aiofiles>=23.2.0",
    "lxml-stubs>=0.5.1", # lxml type hints
    "redis>=6.4.0",
]

docs = ["mkdocs-material>=9.6.23"]


[project.urls]
Homepage = "https://www.qcrawl.org/"
Repository = "https://github.com/crawlcore/qcrawl"
Issues = "https://github.com/crawlcore/qcrawl/issues"
Documentation = "https://www.qcrawl.org/"

# CLI entry point
[project.scripts]
qcrawl = "qcrawl.cli:main"

# Build system
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

# Hatch-specific config (optional but recommended)
[tool.hatch.build.targets.wheel]
packages = ["qcrawl"]

# === Tool Configurations ===

[tool.ruff]
line-length = 100

# Minimum Python version to target for syntax/features
target-version = "py311"

[tool.ruff.lint]
# Rules to enable (https://docs.astral.sh/ruff/rules/)
select = [
    "E",   # pycodestyle errors (PEP 8 violations)
    "F",   # pyflakes (undefined names, unused imports)
    "I",   # isort (import sorting/organization)
    "UP",  # pyupgrade (modern Python syntax)
    "B",   # flake8-bugbear (common bugs and design problems)
    "C4",  # flake8-comprehensions (better list/dict/set comprehensions)
    "SIM", # flake8-simplify (code simplification suggestions)
]

# Rules to disable/ignore
ignore = [
    "E501",  # Line too long (handled by formatter, not Flake8)
]

# === Per-File Rule Overrides ===
[tool.ruff.lint.per-file-ignores]
"tests/*" = ["S101"]    # Allow assert statements in tests
"examples/*" = ["T201"]  # Allow print() in examples

[tool.mypy]
python_version = "3.11"
strict = true
#warn_unused_configs = true
#ignore_missing_imports = true
disable_error_code = [
  "no-untyped-def",      # missing function args/return
  "no-untyped-call",     # calling untyped function
  "var-annotated",       # missing variable type
  "misc",                # generator item mismatch, etc.
  "attr-defined"         # third-party missing attr (e.g. robotstxt)
]

[tool.pytest.ini_options]
addopts = "-ra -q --cov=qcrawl --cov-report=term-missing"
pythonpath = ["."]
asyncio_mode = "auto"
testpaths = ["tests"]
python_files = ["test_*.py", "tests_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]

[tool.coverage.run]
source = ["qcrawl"]
omit = ["*/tests/*", "*/examples/*"]
